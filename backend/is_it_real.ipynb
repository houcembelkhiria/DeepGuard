{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85933dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import threading\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import concurrent.futures\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e7c03",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/kaggle/input/200k-real-vs-ai-visuals-by-mbilal/my_real_vs_ai_dataset/my_real_vs_ai_dataset/\"\n",
    "IMG_SIZE = (128, 128)           # Must match model input!\n",
    "BATCH_SIZE = 128\n",
    "ELA_QUALITY = 75\n",
    "CACHE_DIR = \"/kaggle/working/ela_cache\"  # Kaggle writable dir\n",
    "NUM_THREADS = 8\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8217e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def compute_ela_cv2(img_array: np.ndarray, quality: int = 75) -> np.ndarray:\n",
    "    if img_array.dtype != np.uint8:\n",
    "        img_array = img_array.astype(np.uint8)\n",
    "\n",
    "    img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]\n",
    "    success, enc_img = cv2.imencode('.jpg', img_bgr, encode_param)\n",
    "    if not success:\n",
    "        return np.zeros_like(img_array)\n",
    "\n",
    "    dec_img = cv2.imdecode(enc_img, cv2.IMREAD_COLOR)\n",
    "    dec_rgb = cv2.cvtColor(dec_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    diff = np.abs(img_array.astype(np.int16) - dec_rgb.astype(np.int16))\n",
    "    ela = np.clip(diff * 8, 0, 255).astype(np.uint8)\n",
    "    return ela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a2df4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cache_lock = threading.Lock()\n",
    "\n",
    "def get_cache_path(filepath: str) -> str:\n",
    "    key = f\"{filepath}_{IMG_SIZE[0]}x{IMG_SIZE[1]}_q{ELA_QUALITY}\"\n",
    "    hash_key = hashlib.md5(key.encode()).hexdigest()\n",
    "    return os.path.join(CACHE_DIR, f\"{hash_key}.npy\")\n",
    "\n",
    "def load_or_compute_ela(filepath: str):\n",
    "    cache_path = get_cache_path(filepath)\n",
    "\n",
    "    if os.path.exists(cache_path):\n",
    "        try:\n",
    "            return np.load(cache_path)\n",
    "        except:\n",
    "            pass  # corrupted → recompute\n",
    "\n",
    "    try:\n",
    "        img = Image.open(filepath).convert('RGB')\n",
    "        img = img.resize(IMG_SIZE, Image.Resampling.LANCZOS)\n",
    "        img_array = np.array(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return np.zeros((IMG_SIZE[0], IMG_SIZE[1], 3), dtype=np.uint8)\n",
    "\n",
    "    ela = compute_ela_cv2(img_array, ELA_QUALITY)\n",
    "\n",
    "    with cache_lock:\n",
    "        try:\n",
    "            np.save(cache_path, ela)\n",
    "        except:\n",
    "            pass\n",
    "    return ela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78eafa",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "class FastELASequence(Sequence):\n",
    "    def __init__(self, filepaths, labels, batch_size=BATCH_SIZE, img_size=IMG_SIZE, shuffle=True):\n",
    "        self.filepaths = list(filepaths)\n",
    "        self.labels = np.array(labels, dtype=np.int32)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.filepaths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filepaths) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = min((index + 1) * self.batch_size, len(self.filepaths))\n",
    "        batch_indices = self.indices[start:end]\n",
    "\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "\n",
    "        def load_one(i):\n",
    "            ela = load_or_compute_ela(self.filepaths[i])\n",
    "            batch_x.append(ela)\n",
    "            batch_y.append(self.labels[i])\n",
    "\n",
    "        if len(batch_indices) >= 8:\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "                list(executor.map(load_one, batch_indices))\n",
    "        else:\n",
    "            for i in batch_indices:\n",
    "                load_one(i)\n",
    "\n",
    "        X = np.array(batch_x, dtype=np.float32) / 255.0\n",
    "        y = to_categorical(batch_y, num_classes=NUM_CLASSES)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923aff31",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading filepaths and labels...\")\n",
    "filepaths = []\n",
    "labels = []\n",
    "class_names = [\"ai_images\", \"real\"]\n",
    "class_to_idx = {\"ai_images\": 0, \"real\": 1}\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(DATA_DIR, class_name)\n",
    "    if not os.path.exists(class_dir):\n",
    "        print(f\"Warning: {class_dir} not found!\")\n",
    "        continue\n",
    "    for fname in os.listdir(class_dir):\n",
    "        if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            filepaths.append(os.path.join(class_dir, fname))\n",
    "            labels.append(class_to_idx[class_name])\n",
    "\n",
    "filepaths = np.array(filepaths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Total images: {len(filepaths)}\")\n",
    "print(f\"AI: {np.sum(labels==0)}, Real: {np.sum(labels==1)}\")\n",
    "\n",
    "# Split\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    filepaths, labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_paths)}, Val: {len(val_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b757e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = FastELASequence(train_paths, train_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_gen = FastELASequence(val_paths, val_labels, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9aac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (5,5), activation='relu', input_shape=(128,128,3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(2,2),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (5,5), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(2,2),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(2,2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(2,2),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    \"/kaggle/working/best_model.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=7,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47fbe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training... (First epoch will build ELA cache — be patient!)\")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=70,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save final model\n",
    "model.save(\"/kaggle/working/final_real_vs_ai_ela_model.h5\")\n",
    "# model.save(\"/kaggle/working/final_real_vs_ai_ela_model.keras\")\n",
    "print(\"Training complete! Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120c297",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced58536",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fca316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predict_image(image_path, model_path=model):\n",
    "    model = model_path\n",
    "    \n",
    "    ela = convert_to_ela_image(image_path, quality=95)\n",
    "    ela_resized = ela.resize((128,128))\n",
    "    ela_array = np.array(ela_resized) / 255.0\n",
    "    ela_array = ela_array.reshape(1, 128, 128, 3)\n",
    "    \n",
    "    pred = model.predict(ela_array)[0]\n",
    "    confidence_fake = pred[1] * 100\n",
    "    confidence_real = pred[0] * 100\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(Image.open(image_path))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"ELA (Quality=75)\")\n",
    "    plt.imshow(ela)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(f\"Prediction\\nReal: {confidence_real:.2f}%\\nFake: {confidence_fake:.2f}%\")\n",
    "    plt.bar(['Real', 'Fake'], [confidence_real, confidence_fake], color=['green', 'red'])\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"➜ Prediction: {'Fake' if confidence_fake > 50 else 'Real'}\")\n",
    "    print(f\"➜ Confidence: {max(confidence_fake, confidence_real):.2f}%\")\n",
    "    print(f\"Raw probabilities → Real: {confidence_real:.2f}% | Fake: {confidence_fake:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"\"\n",
    "predict_image(image_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
